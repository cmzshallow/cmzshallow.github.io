---
title: 导出功能优化
date: 2024-04-29 10:03
categories:
  - 系统优化
---

### 场景：由于系统导出数据需要的时间比较久，并且导出大量数据时甚至会导致服务崩溃。

开始排查问题，首先找到查询数据的sql语句，发现其采用了collection标签（系统使用的是mybatis框架），并且使用select参数指定了一个查询另一个表的数据，这样会导致 1+N 问题的出现。

何为 1+N 问题，引用 Mybatis 的案例：
```sql
<resultMap id="blogResult" type="Blog">
	<collection property="posts" ofType="Post" column="id" select="selectPostsForBlog"/>
</resultMap>
```
这种查询会导致每当有一个 Blog 对象，就会去调用一次 selectPostsForBlog 方法去查询 Post 对象列表，如果有十万条数据，则会进行 1 + 10万次查询，浪费性能。
所以，这里应该改成用连表的方式去获取子列表数据：
```sql
<resultMap id="blogResult" type="Blog">
	<collection property="posts" ofType="Post">
		<result column .../>
	</collection>
</resultMap>
```

做完这一步修改后，本地查询17万条数据的速度从开始的380秒变成了10秒左右。

在修改sql语句的过程中发现另一个问题，同样的sql语句，由于导出数据并不需要用到主表的id，所以我select语句没有将主表的id查询出来。但是后面发现，将主表的id查询出来后，系统导出占用的内存差不多是只查子表id，不查主表id的两倍，内存占用如图所示，前两次为不查主表id只查子表id，后两次为主子表id都查。
![c0dd035bab53aa95e8dd0263037f242.png](https://shallowcmz.oss-cn-hangzhou.aliyuncs.com/aurora/articles/ab64273d35f191dee9dead99c7f18af4.png)

暂时未发现是什么原因，留待后续填坑。

修改完上述地方后，导出时查询速度用时长的问题解决了，但是还有导出时间长，以及占用内存大的问题还未解决，原代码使用的是easypoi的导出接口：
```java
Workbook exportExcel(ExportParams entity, Class<?> pojoClass, Collection<?> dataSet)
```
查看了一下easypoi提供的方法，好像并无支持分批写入的方法，也有可能是我未发现，然后就决定改用alibaba提供的easyexcel进行数据分批写入的操作。

一开始我是打算分批查询数据，毕竟十几万数据一次放到内存写出太多，后来发现mybatis提供了流式查询的方法。所谓流式查询，是防止查询出来的数据太多，加载到内存导致OOM，支持将符合条件的数据分批返回（如有不对请指教），这样就可以有效降低服务崩溃的可能性。

那么如何开启流式查询呢，都说需要在mapper.xml文件的select逾期添加resultSetType="FORWARD_ONLY"以及fetchSize="-2147483648"，但是我尝试了一下去掉这两个参数，发现区别不大，如下图所示。（这里也留了个坑待填）
![image.png](https://shallowcmz.oss-cn-hangzhou.aliyuncs.com/aurora/articles/035774cb8de6c9b34451cf74013d5198.png)

然后我调用的mapper方法如下：
```java
void listObjectsForExport(@Param("query") Object query, ResultHandler<?> resultHandler);
```

重点在于传入ResultHandler，自己去操控返回来的数据，同时流式查询的返回类型需要改成void，这个与cursor，游标查询需要返回Cursor<Object>有带不一样。

我为了系统均可用这个导出的方法，所以进行了抽象，抽象出来的方法如下：
```java
/**
 *
 * @param response 
 * @param fileName 导出文件名
 * @param excelClass 导出的 excelDTO 的类型
 * @param querier mapper的查询方法
 * @param query 查询对象
 * @param converter 将实体转成 excelDTO 的方法
 * @param <T> 实体类
 * @param <E> 查询对象
 * @param <D> 导出 DTO 类
 */
public <T, E, D> void export(HttpServletResponse response, String fileName, Class<D> excelClass, 
				BiConsumer<E, ResultHandler<T>> querier, E query, Function<T, List<D>> converter) {
    try {
        long start = System.currentTimeMillis();
        response.setCharacterEncoding("UTF-8");
        response.setHeader("content-Type", "application/vnd.ms-excel");
        response.setHeader("Content-Disposition", "attachment;filename=" + URLEncoder.encode(fileName + ".xlsx", StandardCharsets.UTF_8));

        ExcelWriter writer = new ExcelWriterBuilder().file(response.getOutputStream()).build();

            // 设置表格
        WriteSheet sheet = new WriteSheet();
        sheet.setSheetName(fileName);

        List<List<String>> heads = new ArrayList<>();
        List<String> params = new ArrayList<>();
        for (Field declaredField : excelClass.getDeclaredFields()) {
            declaredField.setAccessible(true);
            // 获取导出的列的名称以及对应的参数名称
            if (declaredField.isAnnotationPresent(HyplatformExcel.class)) {
                HyplatformExcel annotation = declaredField.getAnnotation(HyplatformExcel.class);
                    heads.add(Collections.singletonList(annotation.columnName()));
                params.add(declaredField.getName());
            }
        }

        // 设置标题
        WriteTable table = new WriteTable();
        table.setHead(heads);

        List<List<String>> results = new ArrayList<>();
        ResultHandler<T> resultHandler = resultContext -> {
            T t = resultContext.getResultObject();
            // 转换成导出对象
            List<D> excels = converter.apply(t);
            for (D excel : excels) {
                Map<String, Object> beanMap = BeanUtil.beanToMap(excel);
                List<String> values = new ArrayList<>(heads.size());
		// 根据上面注解获取的参数名获取参数值
                for (String param : params) {
                    Object value = beanMap.get(param);
                    if (null == value) {
                        value = "";
                    }
                    values.add(value.toString());
                }
                results.add(values);
            }

            writer.write(results, sheet, table);
            results.clear();
        };

        querier.accept(query, resultHandler);
        writer.finish();
        long end = System.currentTimeMillis();
        System.out.println("end:" + (end - start) / 1000);
    } catch (Exception e) {
        e.printStackTrace();
    }
}
```

优化后与优化前的内存占比对比图如下：
![image.png](https://shallowcmz.oss-cn-hangzhou.aliyuncs.com/aurora/articles/441d172dee99f46e88a9a546a8d07fb5.png)
第三个是我尝试用游标分批查询以及写入的占比，发现和单条获取并且写入并没什么区别，于是还是采用了单条获取并写入的方法，这里由于我还未查询主表id，所以内存占用也较高，完整的修改后的内存占比图则是一开始就展示的图了：
![c0dd035bab53aa95e8dd0263037f242.png](https://shallowcmz.oss-cn-hangzhou.aliyuncs.com/aurora/articles/ab64273d35f191dee9dead99c7f18af4.png)

相比原来的4G内存占用以及查询速度和导出速度的缓慢，现在导出17w+数据总共花费16秒左右，内存占用则不足300MB（不一定准确，但是就算是1G，相比原来进步也很大了），可能还有优化的空间，也有很多的坑未填，等待后续填坑~
